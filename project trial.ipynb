{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# ! pip install wildlife-tools\n","# ! pip install wildlife-datasets\n","# ! git clone https://github.com/WildlifeDatasets/wildlife-tools"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T20:05:15.211938Z","iopub.status.busy":"2024-05-09T20:05:15.211477Z","iopub.status.idle":"2024-05-09T20:05:17.157845Z","shell.execute_reply":"2024-05-09T20:05:17.155766Z","shell.execute_reply.started":"2024-05-09T20:05:15.211907Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import matplotlib.pyplot as plt\n","import torch\n","import pandas as pd\n","import torchvision.transforms as T\n","import timm\n","\n","from wildlife_datasets import datasets\n","from wildlife_tools.data import WildlifeDataset\n","from wildlife_tools.features import DeepFeatures\n","from wildlife_tools.similarity import CosineSimilarity\n","from wildlife_tools.inference import KnnClassifier"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.status.busy":"2024-05-09T19:53:01.645751Z","iopub.status.idle":"2024-05-09T19:53:01.646205Z","shell.execute_reply":"2024-05-09T19:53:01.646020Z","shell.execute_reply.started":"2024-05-09T19:53:01.646001Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DATASET MPDD: DOWNLOADING STARTED.\n"]},{"name":"stderr","output_type":"stream","text":["v5j6m8dzhv-1.zip: 29.6MB [00:20, 1.43MB/s]                              \n"]},{"name":"stdout","output_type":"stream","text":["DATASET MPDD: EXTRACTING STARTED.\n","DATASET MPDD: FINISHED.\n","\n"]}],"source":["# dataset = datasets.MPDD('data\\\\MPDD')\n","\n","root = 'data\\\\MPDD'\n","datasets.MPDD.get_data(root)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.status.busy":"2024-05-09T19:53:01.647801Z","iopub.status.idle":"2024-05-09T19:53:01.648418Z","shell.execute_reply":"2024-05-09T19:53:01.648140Z","shell.execute_reply.started":"2024-05-09T19:53:01.648117Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["This dataset is outdated. You may want to call a newer version such as FriesianCattle2015v2.\n"]}],"source":["d = datasets.FriesianCattle2015(root)\n","dataset = WildlifeDataset(d.df, d.root)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.status.busy":"2024-05-09T19:53:01.650287Z","iopub.status.idle":"2024-05-09T19:53:01.650860Z","shell.execute_reply":"2024-05-09T19:53:01.650604Z","shell.execute_reply.started":"2024-05-09T19:53:01.650581Z"},"trusted":true},"outputs":[],"source":["model_name = 'hf-hub:BVRA/MegaDescriptor-T-224'\n","model = timm.create_model(model_name, num_classes=0, pretrained=True)\n","transform = T.Compose([T.Resize([224, 224]), T.ToTensor(), T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n","extractor = DeepFeatures(model)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.status.busy":"2024-05-09T19:53:01.653271Z","iopub.status.idle":"2024-05-09T19:53:01.653991Z","shell.execute_reply":"2024-05-09T19:53:01.653633Z","shell.execute_reply.started":"2024-05-09T19:53:01.653612Z"},"trusted":true},"outputs":[],"source":["df1 = dataset.metadata[dataset.metadata['identity'] == 1]\n","df2 = dataset.metadata[dataset.metadata['identity'] == 2]\n","df_database = pd.concat((df1.iloc[2:], df2.iloc[2:]))\n","df_query = pd.concat((df1.iloc[:2], df2.iloc[:2]))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.status.busy":"2024-05-09T19:53:01.655620Z","iopub.status.idle":"2024-05-09T19:53:01.656072Z","shell.execute_reply":"2024-05-09T19:53:01.655906Z","shell.execute_reply.started":"2024-05-09T19:53:01.655875Z"},"trusted":true},"outputs":[],"source":["d_database = WildlifeDataset(df_database, d.root, transform=transform, img_load='crop_black')\n","d_query = WildlifeDataset(df_query, d.root, transform=transform, img_load='crop_black')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.status.busy":"2024-05-09T19:53:01.658456Z","iopub.status.idle":"2024-05-09T19:53:01.658981Z","shell.execute_reply":"2024-05-09T19:53:01.658761Z","shell.execute_reply.started":"2024-05-09T19:53:01.658743Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|                                                                         | 0/1 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|█████████████████████████████████████████████████████████████████| 1/1 [00:25<00:00, 25.17s/it]\n","100%|█████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.64s/it]\n"]}],"source":["database = extractor(d_database)\n","query = extractor(d_query)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["(144, 16)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df_database.size, df_query.size"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.status.busy":"2024-05-09T19:53:01.660391Z","iopub.status.idle":"2024-05-09T19:53:01.660804Z","shell.execute_reply":"2024-05-09T19:53:01.660642Z","shell.execute_reply.started":"2024-05-09T19:53:01.660626Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Python312\\Lib\\site-packages\\wildlife_tools\\inference\\classifier.py:61: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  results = pd.DataFrame(results).T.fillna(method=\"ffill\").T\n"]}],"source":["# from wildlife_tools.inference import KnnMatcher\n","\n","# matcher = KnnMatcher(database)\n","# matcher_output =[]\n","# for i in outputs:\n","#     matcher_output.append(matcher([i]))\n","\n","\n","similarity_function = CosineSimilarity()\n","similarity = similarity_function(query, database)['cosine']\n","classifier = KnnClassifier(k=1, database_labels=d_database.labels_string)\n","predictions = classifier(similarity)\n","\n","\n","print(len(predictions))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["array(['1', '1', '2', '2'], dtype=object)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["40"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["len(set(dataset.metadata.identity))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from PIL import Image\n","\n","def extract_features(image_path):\n","    img = Image.open(r'data\\FriesianCattle2015\\\\'+image_path)\n","    img_tensor = transform(img).unsqueeze(0)  # Transform image and add batch dimension\n","    with torch.no_grad():\n","        features = model(img_tensor)  # Extract features using the pre-trained model\n","    return features\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"The size of tensor a (2) must match the size of tensor b (38) at non-singleton dimension 0","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[19], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m query_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([extract_features(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df_concat\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39miterrows()])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Similarity calculation (cosine similarity)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Classification (assigning labels based on highest similarity)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(similarity, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (38) at non-singleton dimension 0"]}],"source":["df1 = dataset.metadata[dataset.metadata['identity'] == 1]\n","df2 = dataset.metadata[dataset.metadata['identity'] == 2]\n","df_concat = pd.concat([df1, df2])\n","\n","# Extract features for database and query images\n","database_features = torch.cat([extract_features(row['path']) for _, row in df_concat.iloc[2:].iterrows()])\n","query_features = torch.cat([extract_features(row['path']) for _, row in df_concat.iloc[:2].iterrows()])\n","\n","\n","# Similarity calculation (cosine similarity)\n","similarity = torch.nn.functional.cosine_similarity(query_features, database_features, dim=1)\n","\n","# Classification (assigning labels based on highest similarity)\n","predictions = torch.argmax(similarity, dim=1)\n","\n","print(predictions.tolist())  # Print the predicted labels\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["144"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["similarity.size"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
